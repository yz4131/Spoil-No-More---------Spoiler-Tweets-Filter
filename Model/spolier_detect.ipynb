{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4802125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::176363299110:role/service-role/AmazonSageMaker-ExecutionRole-20220425T104815\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "bucket_name = 'elen6889'\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket_key_prefix = 'spoiler-classifier'\n",
    "vocabulary_length = 9013\n",
    "\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b7ac137",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56f2222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  dataset/archive.zip\n",
      "  inflating: dataset/IMDB_movie_details.json  \n",
      "  inflating: dataset/IMDB_reviews.json  \n"
     ]
    }
   ],
   "source": [
    "!unzip -o dataset/archive.zip -d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a906d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from classifier_utilities import one_hot_encode\n",
    "from classifier_utilities import vectorize_sequences\n",
    "#df_reviews = pd.read_json('dataset/IMDB_reviews.json', lines=True)\n",
    "df_review = pd.read_csv('dataset/df.csv')\n",
    "#print('User reviews shape: ', df_reviews.shape)\n",
    "#df[df.columns[0]] = df[df.columns[0]].map({'True': 0, 'False': 1})\n",
    "df = pd.DataFrame()\n",
    "df['is_spoiler'] = df_review['is_spoiler']\n",
    "df['text'] = df_review['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e35ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[0]] = df[df.columns[0]].map({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6130567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af824b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spoiler</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0</td>\n",
       "      <td>What constitutes horror?  Many people say it's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0</td>\n",
       "      <td>This is one of only two movies I can recall wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>Yet another dry humorred spoof of a documentar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_spoiler                                               text\n",
       "406           0  What constitutes horror?  Many people say it's...\n",
       "167           0  This is one of only two movies I can recall wa...\n",
       "63            0  Yet another dry humorred spoof of a documentar..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "862744e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = df[df.columns[0]].values\n",
    "messages = df[df.columns[1]].values\n",
    "\n",
    "# one hot encoding for each SMS message\n",
    "one_hot_data = one_hot_encode(messages, vocabulary_length)\n",
    "encoded_messages = vectorize_sequences(one_hot_data, vocabulary_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "34844dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This movie has sarcasm, lots and lots of humour, great dialogue, pathos, brilliant acting and senes of things blowing up all rolled into one ace movie! Kirsten Dunst really does shine out in this movie and I think she has so much potential to be a big star if she gets a role in a blockbuster movie.  The humour in this movie is great and I love the scenes where we see how the cast die and especially my favourite scene where Denise Richards dances with the Jesus doll and you people who thought that was blasphemy, get a life it was just harmless fun.  Whoever wrote this script is a genius and has loads of great one off lines so listen out for them. Rating 7.5/10'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "caf4fab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a1b5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(encoded_messages)\n",
    "df2.insert(0, 'spam', targets)\n",
    "\n",
    "# Split into training and validation sets (80%/20% split)\n",
    "split_index = int(np.ceil(df.shape[0] * 0.8))\n",
    "train_set = df2[:split_index]\n",
    "val_set = df2[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "675562a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv('dataset/sms_train_set.gz', header=False, index=False, compression='gzip')\n",
    "val_set.to_csv('dataset/sms_val_set.gz', header=False, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "81958193",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "target_bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "with open('dataset/sms_train_set.gz', 'rb') as data:\n",
    "    target_bucket.upload_fileobj(data, '{0}/train/sms_train_set.gz'.format(bucket_key_prefix))\n",
    "    \n",
    "with open('dataset/sms_val_set.gz', 'rb') as data:\n",
    "    target_bucket.upload_fileobj(data, '{0}/val/sms_val_set.gz'.format(bucket_key_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4766b173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from __future__ import print_function\r\n",
      "\r\n",
      "import logging\r\n",
      "import mxnet as mx\r\n",
      "from mxnet import gluon, autograd\r\n",
      "from mxnet.gluon import nn\r\n",
      "import numpy as np\r\n",
      "import json\r\n",
      "import time\r\n",
      "\r\n",
      "import pip\r\n",
      "\r\n",
      "try:\r\n",
      "    from pip import main as pipmain\r\n",
      "except:\r\n",
      "    from pip._internal import main as pipmain\r\n",
      "\r\n",
      "pipmain(['install', 'pandas'])\r\n",
      "import pandas\r\n",
      "\r\n",
      "#logging.basicConfig(level=logging.DEBUG)\r\n",
      "\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "# Training methods                                             #\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "\r\n",
      "\r\n",
      "def train(hyperparameters, input_data_config, channel_input_dirs, output_data_dir,\r\n",
      "          num_gpus, num_cpus, hosts, current_host, **kwargs):\r\n",
      "    # SageMaker passes num_cpus, num_gpus and other args we can use to tailor training to\r\n",
      "    # the current container environment, but here we just use simple cpu context.\r\n",
      "    ctx = mx.cpu()\r\n",
      "\r\n",
      "    # retrieve the hyperparameters and apply some defaults in case they are not provided.\r\n",
      "    batch_size = hyperparameters.get('batch_size', 100)\r\n",
      "    epochs = hyperparameters.get('epochs', 10)\r\n",
      "    learning_rate = hyperparameters.get('learning_rate', 0.01)\r\n",
      "    momentum = hyperparameters.get('momentum', 0.9)\r\n",
      "    log_interval = hyperparameters.get('log_interval', 200)\r\n",
      "\r\n",
      "    train_data_path = channel_input_dirs['train']\r\n",
      "    val_data_path = channel_input_dirs['val']\r\n",
      "    train_data = get_train_data(train_data_path, batch_size)\r\n",
      "    val_data = get_val_data(val_data_path, batch_size)\r\n",
      "\r\n",
      "    # define the network\r\n",
      "    net = define_network()\r\n",
      "\r\n",
      "    # Collect all parameters from net and its children, then initialize them.\r\n",
      "    net.initialize(mx.init.Normal(sigma=1.), ctx=ctx)\r\n",
      "    \r\n",
      "    # Trainer is for updating parameters with gradient.\r\n",
      "    if len(hosts) == 1:\r\n",
      "        kvstore = 'device' if num_gpus > 0 else 'local'\r\n",
      "    else:\r\n",
      "        kvstore = 'dist_device_sync' if num_gpus > 0 else 'dist_sync'\r\n",
      "\r\n",
      "    trainer = gluon.Trainer(net.collect_params(), 'sgd',\r\n",
      "                            {'learning_rate': learning_rate, 'momentum': momentum},\r\n",
      "                            kvstore=kvstore)\r\n",
      "    \r\n",
      "    metric = mx.metric.Accuracy()\r\n",
      "    loss = gluon.loss.SigmoidBinaryCrossEntropyLoss()\r\n",
      "\r\n",
      "    for epoch in range(epochs):\r\n",
      "        \r\n",
      "        # reset data iterator and metric at begining of epoch.\r\n",
      "        metric.reset()\r\n",
      "        btic = time.time()\r\n",
      "        for i, (data, label) in enumerate(train_data):\r\n",
      "            # Copy data to ctx if necessary\r\n",
      "            data = data.as_in_context(ctx)\r\n",
      "            label = label.as_in_context(ctx)\r\n",
      "            \r\n",
      "            # Start recording computation graph with record() section.\r\n",
      "            # Recorded graphs can then be differentiated with backward.\r\n",
      "            with autograd.record():\r\n",
      "                output = net(data)\r\n",
      "                L = loss(output, label)\r\n",
      "            L.backward()\r\n",
      "\r\n",
      "            # take a gradient step with batch_size equal to data.shape[0]\r\n",
      "            trainer.step(data.shape[0])\r\n",
      "\r\n",
      "            # update metric at last.\r\n",
      "            sigmoid_output = output.sigmoid() \r\n",
      "            prediction = mx.nd.abs(mx.nd.ceil(sigmoid_output - 0.5))\r\n",
      "            metric.update([label], [prediction])\r\n",
      "\r\n",
      "            if i % log_interval == 0 and i > 0:\r\n",
      "                name, acc = metric.get()\r\n",
      "                print('[Epoch %d Batch %d] Training: %s=%f, %f samples/s' %\r\n",
      "                      (epoch, i, name, acc, batch_size / (time.time() - btic)))\r\n",
      "\r\n",
      "            btic = time.time()\r\n",
      "\r\n",
      "        name, acc = metric.get()\r\n",
      "        print('[Epoch %d] Training: %s=%f' % (epoch, name, acc))\r\n",
      "\r\n",
      "        name, val_acc = test(ctx, net, val_data)\r\n",
      "        print('[Epoch %d] Validation: %s=%f' % (epoch, name, val_acc))\r\n",
      "\r\n",
      "    return net\r\n",
      "\r\n",
      "def save(net, model_dir):\r\n",
      "    y = net(mx.sym.var('data'))\r\n",
      "    y.save('%s/model.json' % model_dir)\r\n",
      "    net.collect_params().save('%s/model.params' % model_dir)\r\n",
      "\r\n",
      "def define_network():\r\n",
      "    net = nn.Sequential()\r\n",
      "    with net.name_scope():\r\n",
      "        net.add(nn.Dense(64, activation=\"relu\"))\r\n",
      "        net.add(nn.Dense(1))\r\n",
      "    return net\r\n",
      "\r\n",
      "def get_train_data(data_path, batch_size):\r\n",
      "    print('Train data path: ' + data_path)\r\n",
      "    df = pandas.read_csv(data_path + '/sms_train_set.gz')\r\n",
      "    features = df[df.columns[1:]].values.astype(dtype=np.float32)\r\n",
      "    labels = df[df.columns[0]].values.reshape((-1, 1)).astype(dtype=np.float32)\r\n",
      "    \r\n",
      "    return gluon.data.DataLoader(gluon.data.ArrayDataset(features, labels), batch_size=batch_size, shuffle=True)\r\n",
      "\r\n",
      "def get_val_data(data_path, batch_size):\r\n",
      "    print('Validation data path: ' + data_path)\r\n",
      "    df = pandas.read_csv(data_path + '/sms_val_set.gz')\r\n",
      "    features = df[df.columns[1:]].values.astype(dtype=np.float32)\r\n",
      "    labels = df[df.columns[0]].values.reshape((-1, 1)).astype(dtype=np.float32)\r\n",
      "    \r\n",
      "    return gluon.data.DataLoader(gluon.data.ArrayDataset(features, labels), batch_size=batch_size, shuffle=False)\r\n",
      "\r\n",
      "def test(ctx, net, val_data):\r\n",
      "    metric = mx.metric.Accuracy()\r\n",
      "    for data, label in val_data:\r\n",
      "        data = data.as_in_context(ctx)\r\n",
      "        label = label.as_in_context(ctx)\r\n",
      "        \r\n",
      "        output = net(data)\r\n",
      "        sigmoid_output = output.sigmoid() \r\n",
      "        prediction = mx.nd.abs(mx.nd.ceil(sigmoid_output - 0.5))\r\n",
      "        \r\n",
      "        metric.update([label], [prediction])\r\n",
      "    return metric.get()\r\n",
      "\r\n",
      "\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "# Hosting methods                                              #\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "\r\n",
      "\r\n",
      "def model_fn(model_dir):\r\n",
      "    net = gluon.nn.SymbolBlock(\r\n",
      "        outputs=mx.sym.load('%s/model.json' % model_dir),\r\n",
      "        inputs=mx.sym.var('data'))\r\n",
      "    \r\n",
      "    net.load_params('%s/model.params' % model_dir, ctx=mx.cpu())\r\n",
      "\r\n",
      "    return net\r\n",
      "\r\n",
      "def transform_fn(net, data, input_content_type, output_content_type):\r\n",
      "    try:\r\n",
      "        parsed = json.loads(data)\r\n",
      "        nda = mx.nd.array(parsed)\r\n",
      "        \r\n",
      "        output = net(nda)\r\n",
      "        sigmoid_output = output.sigmoid()\r\n",
      "        prediction = mx.nd.abs(mx.nd.ceil(sigmoid_output - 0.5))\r\n",
      "        \r\n",
      "        output_obj = {}\r\n",
      "        output_obj['predicted_label'] = prediction.asnumpy().tolist()\r\n",
      "        output_obj['predicted_probability'] = sigmoid_output.asnumpy().tolist()\r\n",
      "\r\n",
      "        response_body = json.dumps(output_obj)\r\n",
      "        return response_body, output_content_type\r\n",
      "    except Exception as ex:\r\n",
      "        response_body = '{error: }' + str(ex)\r\n",
      "        return response_body, output_content_type\r\n",
      "    "
     ]
    }
   ],
   "source": [
    "!cat 'sms_spam_classifier_mxnet_script.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4faccffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-25 19:32:00 Starting - Starting the training job...\n",
      "2022-04-25 19:32:24 Starting - Preparing the instances for trainingProfilerReport-1650915119: InProgress\n",
      "......\n",
      "2022-04-25 19:33:27 Downloading - Downloading input data...\n",
      "2022-04-25 19:33:48 Training - Training image download completed. Training in progress.\u001b[34m2022-04-25 19:33:49,824 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[34m2022-04-25 19:33:49,824 INFO - root - starting train task\u001b[0m\n",
      "\u001b[34m2022-04-25 19:33:49,828 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[34m2022-04-25 19:33:50,657 WARNING - mxnet_container.train - #033[1;33mThis required structure for training scripts will be deprecated with the next major release of MXNet images. The train() function will no longer be required; instead the training script must be able to be run as a standalone script. For more information, see https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/mxnet#updating-your-mxnet-training-script.#033[1;0m\u001b[0m\n",
      "\u001b[34m2022-04-25 19:33:50,664 INFO - mxnet_container.train - MXNetTrainingEnvironment: {'model_dir': '/opt/ml/model', 'output_data_dir': '/opt/ml/output/data/', '_scheduler_host': 'algo-1', 'container_log_level': 20, 'output_dir': '/opt/ml/output', 'current_host': 'algo-1', 'channel_dirs': {'train': '/opt/ml/input/data/train', 'val': '/opt/ml/input/data/val'}, 'channels': {'train': {'TrainingInputMode': 'File', 'S3DistributionType': 'FullyReplicated', 'RecordWrapperType': 'None'}, 'val': {'TrainingInputMode': 'File', 'S3DistributionType': 'FullyReplicated', 'RecordWrapperType': 'None'}}, 'resource_config': {'current_instance_type': 'ml.c5.2xlarge', 'current_group_name': 'homogeneousCluster', 'network_interface_name': 'eth0', 'current_host': 'algo-1', 'instance_groups': [{'instance_type': 'ml.c5.2xlarge', 'instance_group_name': 'homogeneousCluster', 'hosts': ['algo-1']}], 'hosts': ['algo-1']}, 'user_script_archive': 's3://elen6889/spoiler-classifier/code/sms-spam-classifier-mxnet-2022-04-25-19-31-59-622/source/sourcedir.tar.gz', '_scheduler_ip': '10.0.85.104', 'hyperparameters': {'sagemaker_container_log_level': 20, 'sagemaker_submit_directory': 's3://elen6889/spoiler-classifier/code/sms-spam-classifier-mxnet-2022-04-25-19-31-59-622/source/sourcedir.tar.gz', 'epochs': 20, 'sagemaker_job_name': 'sms-spam-classifier-mxnet-2022-04-25-19-31-59-622', 'sagemaker_region': 'us-east-1', 'batch_size': 100, 'learning_rate': 0.01, 'sagemaker_program': 'sms_spam_classifier_mxnet_script.py'}, 'available_cpus': 8, 'code_dir': '/opt/ml/code', 'enable_cloudwatch_metrics': False, 'user_script_name': 'sms_spam_classifier_mxnet_script.py', '_ps_port': 8000, 'user_requirements_file': None, 'sagemaker_region': 'us-east-1', 'job_name': 'sms-spam-classifier-mxnet-2022-04-25-19-31-59-622', 'input_config_dir': '/opt/ml/input/config', 'hosts': ['algo-1'], 'base_dir': '/opt/ml', 'available_gpus': 0, 'input_dir': '/opt/ml/input', '_ps_verbose': 0}\u001b[0m\n",
      "\u001b[34mDownloading s3://elen6889/spoiler-classifier/code/sms-spam-classifier-mxnet-2022-04-25-19-31-59-622/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[34m2022-04-25 19:33:50,906 INFO - mxnet_container.train - Starting distributed training task\u001b[0m\n",
      "\u001b[34mCollecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/60/2e/dec1cc18c51b8df33c7c4d0a321b084cf38e1733b98f9d15018880fb4970/pytz-2022.1-py2.py3-none-any.whl (503kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.5/dist-packages (from pandas) (1.14.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas) (2.7.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.5/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pytz, pandas\u001b[0m\n",
      "\u001b[34mSuccessfully installed pandas-0.24.2 pytz-2022.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3.4 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.5/dist-packages/mxnet_container/train.py:190: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  train_args = inspect.getargspec(user_module.train)\u001b[0m\n",
      "\u001b[34mTrain data path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mValidation data path: /opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34m[Epoch 0] Training: accuracy=0.555347\u001b[0m\n",
      "\u001b[34m[Epoch 0] Validation: accuracy=0.566416\u001b[0m\n",
      "\u001b[34m[Epoch 1] Training: accuracy=0.684803\u001b[0m\n",
      "\u001b[34m[Epoch 1] Validation: accuracy=0.666667\u001b[0m\n",
      "\u001b[34m[Epoch 2] Training: accuracy=0.729831\u001b[0m\n",
      "\u001b[34m[Epoch 2] Validation: accuracy=0.659148\u001b[0m\n",
      "\u001b[34m[Epoch 3] Training: accuracy=0.716073\u001b[0m\n",
      "\u001b[34m[Epoch 3] Validation: accuracy=0.626566\u001b[0m\n",
      "\u001b[34m[Epoch 4] Training: accuracy=0.719825\u001b[0m\n",
      "\u001b[34m[Epoch 4] Validation: accuracy=0.664160\u001b[0m\n",
      "\u001b[34m[Epoch 5] Training: accuracy=0.725453\u001b[0m\n",
      "\u001b[34m[Epoch 5] Validation: accuracy=0.654135\u001b[0m\n",
      "\u001b[34m[Epoch 6] Training: accuracy=0.732333\u001b[0m\n",
      "\u001b[34m[Epoch 6] Validation: accuracy=0.641604\u001b[0m\n",
      "\u001b[34m[Epoch 7] Training: accuracy=0.717949\u001b[0m\n",
      "\u001b[34m[Epoch 7] Validation: accuracy=0.621554\u001b[0m\n",
      "\u001b[34m[Epoch 8] Training: accuracy=0.675422\u001b[0m\n",
      "\u001b[34m[Epoch 8] Validation: accuracy=0.604010\u001b[0m\n",
      "\u001b[34m[Epoch 9] Training: accuracy=0.722952\u001b[0m\n",
      "\u001b[34m[Epoch 9] Validation: accuracy=0.651629\u001b[0m\n",
      "\u001b[34m[Epoch 10] Training: accuracy=0.702314\u001b[0m\n",
      "\u001b[34m[Epoch 10] Validation: accuracy=0.694236\u001b[0m\n",
      "\u001b[34m[Epoch 11] Training: accuracy=0.743590\u001b[0m\n",
      "\u001b[34m[Epoch 11] Validation: accuracy=0.669173\u001b[0m\n",
      "\u001b[34m[Epoch 12] Training: accuracy=0.732333\u001b[0m\n",
      "\u001b[34m[Epoch 12] Validation: accuracy=0.651629\u001b[0m\n",
      "\u001b[34m[Epoch 13] Training: accuracy=0.724203\u001b[0m\n",
      "\u001b[34m[Epoch 13] Validation: accuracy=0.666667\u001b[0m\n",
      "\u001b[34m[Epoch 14] Training: accuracy=0.742964\u001b[0m\n",
      "\u001b[34m[Epoch 14] Validation: accuracy=0.651629\u001b[0m\n",
      "\u001b[34m[Epoch 15] Training: accuracy=0.743590\u001b[0m\n",
      "\u001b[34m[Epoch 15] Validation: accuracy=0.634085\u001b[0m\n",
      "\u001b[34m[Epoch 16] Training: accuracy=0.731082\u001b[0m\n",
      "\u001b[34m[Epoch 16] Validation: accuracy=0.704261\u001b[0m\n",
      "\u001b[34m[Epoch 17] Training: accuracy=0.749218\u001b[0m\n",
      "\u001b[34m[Epoch 17] Validation: accuracy=0.681704\u001b[0m\n",
      "\u001b[34m[Epoch 18] Training: accuracy=0.736710\u001b[0m\n",
      "\u001b[34m[Epoch 18] Validation: accuracy=0.681704\u001b[0m\n",
      "\u001b[34m[Epoch 19] Training: accuracy=0.761101\u001b[0m\n",
      "\u001b[34m[Epoch 19] Validation: accuracy=0.674185\u001b[0m\n",
      "\n",
      "2022-04-25 19:34:24 Uploading - Uploading generated training model\n",
      "2022-04-25 19:34:24 Completed - Training job completed\n",
      "Training seconds: 57\n",
      "Billable seconds: 57\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "output_path = 's3://{0}/{1}/output'.format(bucket_name, bucket_key_prefix)\n",
    "code_location = 's3://{0}/{1}/code'.format(bucket_name, bucket_key_prefix)\n",
    "\n",
    "m = MXNet('sms_spam_classifier_mxnet_script.py',\n",
    "          role=role,\n",
    "          train_instance_count=1,\n",
    "          instance_type='ml.c5.2xlarge',\n",
    "          output_path=output_path,\n",
    "          base_job_name='sms-spam-classifier-mxnet',\n",
    "          framework_version=\"1.2\",\n",
    "          py_version=\"py3\",\n",
    "          code_location = code_location,\n",
    "          hyperparameters={'batch_size': 100,\n",
    "                         'epochs': 20,\n",
    "                         'learning_rate': 0.01})\n",
    "\n",
    "inputs = {'train': 's3://{0}/{1}/train/'.format(bucket_name, bucket_key_prefix),\n",
    " 'val': 's3://{0}/{1}/val/'.format(bucket_name, bucket_key_prefix)}\n",
    "\n",
    "m.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cac5d4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "mxnet_pred = m.deploy(initial_instance_count=1,\n",
    "                      instance_type='ml.m5.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8bba7454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "{'predicted_label': [[0.0]], 'predicted_probability': [[0.003053836291655898]]}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.mxnet.model import MXNetPredictor\n",
    "from classifier_utilities import one_hot_encode\n",
    "from classifier_utilities import vectorize_sequences\n",
    "\n",
    "# Uncomment the following line to connect to an existing endpoint.\n",
    "#mxnet_pred = MXNetPredictor('classifier-mxnet-2022-04-25-18-34-12-620')\n",
    "\n",
    "test_messages = [\"Along with Q and Pulp Fiction, Frank Darabont (The Walking Dead original writer) and his debut film got screwed by the Hollywood Powerhouse that is Tom Hanks with this now can be considered an American Classic. The fact that this film barely and I emphasize barely made it's money back in US theaters (which is usually a signal for a film to turn into a DOA when released at home) and it made such a splash,\"]\n",
    "one_hot_test_messages = one_hot_encode(test_messages, vocabulary_length)\n",
    "encoded_test_messages = vectorize_sequences(one_hot_test_messages, vocabulary_length)\n",
    "\n",
    "print(encoded_test_messages)\n",
    "\n",
    "result = mxnet_pred.predict(encoded_test_messages)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4c604b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab00b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
